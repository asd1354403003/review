{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "from retrying import retry\n",
    "import re\n",
    "import pyspark\n",
    "import jieba.analyse\n",
    "import jieba\n",
    "import os \n",
    "from os import walk\n",
    "from os import path\n",
    "from sklearn.decomposition import PCA\n",
    "from dask import delayed\n",
    "import dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10073018074035645\n"
     ]
    }
   ],
   "source": [
    "read_time = time.time()\n",
    "df = pd.read_excel('cluster_test.xlsx')\n",
    "print(time.time()-read_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_time = time.time()\n",
    "# #df = pd.read_excel('cluster_test.xlsx')\n",
    "# da_df = dd.read_csv('cluster_test.csv')\n",
    "# print(time.time()-read_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da_df.compute().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_path = 'stopwords.txt' # 停用词词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jiebaclearText(text):\n",
    "    mywordlist = []\n",
    "    seg_list = jieba.cut(text, cut_all=False)\n",
    "    liststr=\"/ \".join(seg_list)\n",
    "    f_stop = open(stopwords_path)\n",
    "\n",
    "    with open('stopwords.txt', 'r', encoding='UTF-8') as f1:\n",
    "        f_stop_text = f1.read()    # 读取数据\n",
    "\n",
    "    \n",
    "    f_stop_seg_list=f_stop_text.split('\\n')\n",
    "    for myword in liststr.split('/'):\n",
    "        if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:\n",
    "            mywordlist.append(myword)\n",
    "    return ''.join(mywordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def delayed_jiebaclearText(text):\n",
    "    mywordlist = []\n",
    "    seg_list = jieba.cut(text, cut_all=False)\n",
    "    liststr=\"/ \".join(seg_list)\n",
    "    f_stop = open(stopwords_path)\n",
    "\n",
    "    with open('stopwords.txt', 'r', encoding='UTF-8') as f1:\n",
    "        f_stop_text = f1.read()    # 读取数据\n",
    "\n",
    "    \n",
    "    f_stop_seg_list=f_stop_text.split('\\n')\n",
    "    for myword in liststr.split('/'):\n",
    "        if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:\n",
    "            mywordlist.append(myword)\n",
    "    return ''.join(mywordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def add(x, y):\n",
    "    return x + ' ' + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = da_df.compute()\n",
    "x = df\n",
    "y = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\13544\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.838 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.849633932113647\n"
     ]
    }
   ],
   "source": [
    "y['contetn_after_jieba'] =1 \n",
    "l = []\n",
    "kai = time.time()\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    content = jiebaclearText(df.content\t[i])\n",
    "    title = jiebaclearText(df.分析对象\t[i])\n",
    "    c = content + ' ' + title\n",
    "    l.append(c)\n",
    "print(time.time() - kai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client()\n",
    "# client.cluster\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.537843942642212\n"
     ]
    }
   ],
   "source": [
    "x['contetn_after_jieba'] =1 \n",
    "dask_l = []\n",
    "kai = time.time()\n",
    "for i in range(len(x)):\n",
    "    content = delayed_jiebaclearText(df.content\t[i])\n",
    "    title = delayed_jiebaclearText(df.分析对象\t[i])\n",
    "    \n",
    "    c = dask.delayed(add)(content, title)\n",
    "    dask_l.append(c)\n",
    "total_pic = dask.delayed(dask_l)\n",
    "total = total_pic.compute(num_workers=2)\n",
    "print(time.time() - kai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今日 发现 能代 CPA 能代 CPB 命运 Cle de Peau Beaute'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = v.fit_transform(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x12851 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 34320 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = asd.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=800)\n",
    "principalComponents = pca.fit_transform(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.10701815e-01, -2.20372522e-01, -4.16628552e-02, ...,\n",
       "        -1.43771053e-18,  1.75499306e-18,  1.98858429e-18],\n",
       "       [-1.07649971e-01, -2.82332100e-01, -4.25626396e-02, ...,\n",
       "        -1.43771053e-18,  1.75499306e-18,  1.98858429e-18],\n",
       "       [-1.11652331e-01, -2.42609448e-01, -5.89410176e-02, ...,\n",
       "        -1.43771053e-18,  1.75499306e-18,  1.98858429e-18],\n",
       "       ...,\n",
       "       [ 3.31562628e-01,  3.19071393e-02,  3.00826402e-02, ...,\n",
       "        -1.43771053e-18,  1.75499306e-18,  1.98858429e-18],\n",
       "       [-1.41762435e-01, -3.22262380e-01,  1.16267773e-01, ...,\n",
       "        -1.43771053e-18,  1.75499306e-18,  1.98858429e-18],\n",
       "       [-5.23170903e-01,  4.10586566e-01, -8.24494408e-02, ...,\n",
       "        -1.43771053e-18,  1.75499306e-18,  1.98858429e-18]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_ml.cluster\n",
    "km  = dask_ml.cluster.KMeans(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = km.predict(principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 3.91 kiB </td> <td> 500 B </td></tr>\n",
       "    <tr><th> Shape </th><td> (1000,) </td> <td> (125,) </td></tr>\n",
       "    <tr><th> Count </th><td> 48 Tasks </td><td> 8 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int32 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1000</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<astype, shape=(1000,), dtype=int32, chunksize=(125,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#许佳琪的小猪仔[超话]#   0501求积分  #许佳琪幻乐森林# #许佳琪做家务的男人# #许佳琪清风朗月花正开# #许佳琪陈朗月# #许佳琪 skin##许佳琪的北漂日记##完美日记许佳琪##许佳琪 植村秀品牌挚友# #雪花秀品牌大使许佳琪##许佳琪 THE9门面主舞# #许佳琪 如意芳霏##许佳琪正能量偶像#   @THE9-许佳琪\n",
      "#许佳琪的小猪仔[超话]#   0501积分  #许佳琪 skin#  #许佳琪清风朗月花正开#  #许佳琪幻乐森林#  #许佳琪 THE9门面主舞#  #雪花秀品牌大使许佳琪#  #完美日记许佳琪#  #许佳琪 植村秀品牌挚友#  #许佳琪正能量偶像# #许佳琪为歌而赞#  @THE9-许佳琪 ​\n",
      "#许佳琪的小猪仔[超话]#   0501积分，指h  #许佳琪幻乐森林# #许佳琪陈朗月# #许佳琪清风朗月花正开# #许佳琪做家务的男人#  #许佳琪 skin# #许佳琪泊山城# #许佳琪傅宣#  #许佳琪 植村秀品牌挚友# #许佳琪正能量偶像#   #雪花秀品牌大使许佳琪# #完美日记许佳琪# @THE9-许佳琪 ​​​ ​​​​\n",
      "#许佳琪的小猪仔[超话]#   求积分#许佳琪陈朗月##许佳琪 skin##许佳琪傅宣# #许佳琪如意芳霏# #许佳琪梁雪# #许佳琪平行迷途# #许佳琪小巨人运动会# #许佳琪正能量偶像# #雪花秀品牌大使许佳琪# #许佳琪 植村秀品牌挚友# #完美日记许佳琪# ​@THE9-许佳琪 ​\n",
      "#许佳琪的小猪仔[超话]#  0501积分  #许佳琪 skin#  #许佳琪清风朗月花正开#  #许佳琪幻乐森林#  #许佳琪 THE9门面主舞#  #雪花秀品牌大使许佳琪#  #完美日记许佳琪#  #许佳琪 植村秀品牌挚友#  #许佳琪正能量偶像# #许佳琪为歌而赞#  @THE9-许佳琪 ​\n",
      "#许佳琪的小猪仔[超话]#   许佳琪陈朗月#许佳琪陈朗月# 许佳琪清风朗月花正开#许佳琪清风朗月花正开# 许佳琪skin#许佳琪 skin# #许佳琪傅宣#  #许佳琪 植村秀品牌挚友# #许佳琪正能量偶像#   #雪花秀品牌大使许佳琪# #完美日记许佳琪# @THE9-许佳琪 ​\n",
      "#许佳琪的小猪仔[超话]#   许佳琪陈朗月#许佳琪陈朗月# 许佳琪清风朗月花正开#许佳琪清风朗月花正开# 许佳琪skin#许佳琪 skin# #许佳琪傅宣#  #许佳琪 植村秀品牌挚友# #许佳琪正能量偶像#   #雪花秀品牌大使许佳琪# #完美日记许佳琪# @THE9-许佳琪 ​\n",
      "#许佳琪的小猪仔[超话]#  0501  #许佳琪做家务的男人# #许佳琪陈朗月# #许佳琪清风朗月花正开# #许佳琪 skin# #许佳琪傅宣#  #许佳琪 植村秀品牌挚友# #许佳琪正能量偶像#  #雪花秀品牌大使许佳琪# #完美日记许佳琪#  @THE9-许佳琪 ​\n",
      "#许佳琪[超话]# 许佳琪陈朗月#许佳琪做家务的男人##许佳琪陈朗月# #许佳琪清风朗月花正开##许佳琪的北漂日记# #许佳琪 skin#  #许佳琪 THE9门面主舞#  #许佳琪 植村秀品牌挚友# #许佳琪正能量偶像#  #珀莱雅青春推荐官 许佳琪#  #雪花秀品牌大使许佳琪#  @THE9-许佳琪\n",
      "#许佳琪的小猪仔[超话]#       0505积分，指h  许佳琪苏若非 #许佳琪苏若非#  许佳琪幻乐森林 #许佳琪幻乐森林#  许佳琪陈朗月 #许佳琪陈朗月#  许佳琪清风朗月花正开 #许佳琪清风朗月花正开#  许佳琪做家务的男人#许佳琪做家务的男人#  许佳琪初入职场的我们 #许佳琪初入职场的我们#  #许佳琪 skin# #许佳琪泊山城# #许佳琪傅宣#  #许佳琪 植村秀品牌挚友# #雪花秀品牌大使许佳琪# #完美日记许佳琪# @THE9-许佳琪 ​​​ ​​​​\n",
      "#许佳琪[超话]#  0505  #许佳琪苏若非#  #许佳琪幻乐森林#  #许佳琪陈朗月#  #许佳琪清风朗月花正开#  #许佳琪做家务的男人#  #许佳琪 skin#   #许佳琪 植村秀品牌挚友#  #雪花秀品牌大使许佳琪#  #完美日记许佳琪##许佳琪时尚频道##许佳琪正能量偶像#@THE9-许佳琪\n",
      "#许佳琪的小猪仔[超话]#  0505  指路回  #许佳琪苏若非##许佳琪蝎子腿##许佳琪做家务的男人##许佳琪陈朗月##许佳琪清风朗月花正开##许佳琪 skin##许佳琪如意芳霏#  #雪花秀品牌大使许佳琪#  #许佳琪 植村秀品牌挚友#   #完美日记许佳琪#  #许佳琪正能量偶像# @THE9-许佳琪 ​​​\n",
      "#许佳琪[超话]#   0505求积分  #许佳琪苏若非#  #许佳琪幻乐森林#  #许佳琪陈朗月#  #许佳琪清风朗月花正开#  #许佳琪做家务的男人#  #许佳琪 skin#   #许佳琪 植村秀品牌挚友#  #雪花秀品牌大使许佳琪#  #完美日记许佳琪##许佳琪时尚频道##许佳琪正能量偶像#@THE9-许佳琪\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y)):\n",
    "    if y[i] == 7:\n",
    "        print(df.content[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>分析对象</th>\n",
       "      <th>content</th>\n",
       "      <th>情感</th>\n",
       "      <th>contetn_after_jieba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Make Up For Ever</td>\n",
       "      <td>天医归来秦羽 夏晓薇(免费/每费）阅读！ 看到野兔，立即放出猎鹰追捕在 木 头 上 ，   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La Mer|Helena Rubinstein</td>\n",
       "      <td>顶级女海王“睡男人”有多野？日版项思醒被扒67张劲爆旧照，王思聪跪服：高端玩家！她，凭借67...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La Mer</td>\n",
       "      <td>光希 眼部精华 | 眼周皮肤紧致后，眼角自然上提，真正做到了无痛眼部线雕！而且不长脂肪粒！人...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La Mer</td>\n",
       "      <td>@欣崽️创作的原声#无龄白挑战 @LA MER海蓝之谜 #全民任务 @DOU+小助手</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Mer</td>\n",
       "      <td>@湘妹心宝创作的原声#无龄白挑战 @LA MER海蓝之谜 #祝福大家五一劳动节快乐</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Cle de Peau Beaute</td>\n",
       "      <td>#蔡徐坤[超话]#[心]#蔡徐坤代言cpb肌肤之钥# [心]#奔跑吧蔡徐坤# [心]#安慕希...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>SK-II</td>\n",
       "      <td>出全新sk2大红瓶面霜80g的</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Cle de Peau Beaute</td>\n",
       "      <td>#奔跑吧蔡徐坤#  #蔡徐坤代言cpb肌肤之钥#   蔡徐坤奔跑吧兄弟蔡徐坤原创音乐制作人才...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Helena Rubinstein</td>\n",
       "      <td>#华晨宇和平精英品牌代言人# hcy  花花 #hr赫莲娜新生护肤代言人华晨宇#   （组内...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Shu Uemura</td>\n",
       "      <td>#王一博植村秀全球品牌代言人# wyb#王一博#wyb#王一博平安喜乐#wyb#王一博冰雨火...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         分析对象  \\\n",
       "0            Make Up For Ever   \n",
       "1    La Mer|Helena Rubinstein   \n",
       "2                      La Mer   \n",
       "3                      La Mer   \n",
       "4                      La Mer   \n",
       "..                        ...   \n",
       "995        Cle de Peau Beaute   \n",
       "996                     SK-II   \n",
       "997        Cle de Peau Beaute   \n",
       "998         Helena Rubinstein   \n",
       "999                Shu Uemura   \n",
       "\n",
       "                                               content  情感  \\\n",
       "0    天医归来秦羽 夏晓薇(免费/每费）阅读！ 看到野兔，立即放出猎鹰追捕在 木 头 上 ，   ...   0   \n",
       "1    顶级女海王“睡男人”有多野？日版项思醒被扒67张劲爆旧照，王思聪跪服：高端玩家！她，凭借67...  -1   \n",
       "2    光希 眼部精华 | 眼周皮肤紧致后，眼角自然上提，真正做到了无痛眼部线雕！而且不长脂肪粒！人...   0   \n",
       "3           @欣崽️创作的原声#无龄白挑战 @LA MER海蓝之谜 #全民任务 @DOU+小助手   0   \n",
       "4            @湘妹心宝创作的原声#无龄白挑战 @LA MER海蓝之谜 #祝福大家五一劳动节快乐   1   \n",
       "..                                                 ...  ..   \n",
       "995  #蔡徐坤[超话]#[心]#蔡徐坤代言cpb肌肤之钥# [心]#奔跑吧蔡徐坤# [心]#安慕希...   0   \n",
       "996                                    出全新sk2大红瓶面霜80g的   0   \n",
       "997  #奔跑吧蔡徐坤#  #蔡徐坤代言cpb肌肤之钥#   蔡徐坤奔跑吧兄弟蔡徐坤原创音乐制作人才...   1   \n",
       "998  #华晨宇和平精英品牌代言人# hcy  花花 #hr赫莲娜新生护肤代言人华晨宇#   （组内...   0   \n",
       "999  #王一博植村秀全球品牌代言人# wyb#王一博#wyb#王一博平安喜乐#wyb#王一博冰雨火...   1   \n",
       "\n",
       "     contetn_after_jieba  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "..                   ...  \n",
       "995                    1  \n",
       "996                    1  \n",
       "997                    1  \n",
       "998                    1  \n",
       "999                    1  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
